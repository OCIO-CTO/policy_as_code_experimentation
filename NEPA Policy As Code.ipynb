{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f031d3e3-0d0b-4eb5-b1ae-c127a8e2a332",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get XML from URL and save to DBFS"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Step 1: Download XML from URL\n",
    "url = \"https://www.federalregister.gov/documents/full_text/xml/2025/07/03/2025-12326.xml\"\n",
    "xml_content = requests.get(url).content\n",
    "\n",
    "# Step 2: Save XML to DBFS\n",
    "with open(\"/dbfs/tmp/2025-12326.xml\", \"wb\") as f:\n",
    "    f.write(xml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c5e2090-c39f-43d3-873c-3c0f1730857f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get the XML rowTag(s)"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Load XML content (from file, string, or URL)\n",
    "tree = ET.parse(\"/dbfs/tmp/example.xml\")  # If you've saved the file to DBFS\n",
    "root = tree.getroot()\n",
    "\n",
    "print(\"Root tag:\", root.tag)\n",
    "print(\"Immediate child tags under root:\")\n",
    "for child in root:\n",
    "    print(child.tag)\n",
    "\n",
    "# Or, if you have the XML content as a string:\n",
    "# root = ET.fromstring(xml_content)\n",
    "# print(\"Root tag:\", root.tag)\n",
    "# print(\"Immediate child tags under root:\")\n",
    "# for child in root:\n",
    "#     print(child.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aff570c9-de96-48e5-bc03-49a296b7455d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read XML to Spark DataFrame"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Read XML to Spark DataFrame (requires Databricks XML library)\n",
    "df = spark.read.format(\"xml\") \\\n",
    "    .option(\"rowTag\", \"YOUR_ROW_TAG\") \\  # Replace with the XML's main row tag\n",
    "    .load(\"dbfs:tmp/2025-12326.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1313852-0be4-466e-bc7b-00b8f2c91165",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Convert DataFrame to Python Dictionary\n",
    "dict_list = [row.asDict() for row in df.collect()]\n",
    "\n",
    "# Step 5: (Optional) Custom Parsing with ElementTree\n",
    "import xml.etree.ElementTree as ET\n",
    "root = ET.fromstring(xml_content)\n",
    "# Traverse and parse as needed to build dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78841173-1f59-4245-adfc-a9eaee3e444b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install xmltodict\n",
    "import xmltodict\n",
    "\n",
    "# Read and parse the XML file\n",
    "with open(\"2025-12326.xml\", \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "    xml_content = file.read()\n",
    "\n",
    "policy_dict = xmltodict.parse(xml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21538f32-8976-4b32-9124-59f930d817e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Refined extraction logic for regulatory requirements and metadata from NEPA XML\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Helper function to identify requirement-like sentences\n",
    "requirement_keywords = [\n",
    "    'must', 'shall', 'required', 'mandate', 'prohibit', 'forbid', 'ensure', 'direct', 'provision', 'deadline', 'limit', 'review', 'prepare', 'submit', 'report', 'determine', 'specify', 'clarify', 'add', 'remove', 'revise', 'publish', 'provide', 'consider', 'apply', 'adopt', 'implement', 'establish', 'define', 'categorical exclusion', 'environmental assessment', 'environmental impact statement'\n",
    "]\n",
    "\n",
    "# Flatten paragraphs from SUPLINF\n",
    "suplinf = policy_dict['RULE']['SUPLINF']\n",
    "paragraphs = []\n",
    "for p in suplinf.get('P', []):\n",
    "    if isinstance(p, str) and p.strip():\n",
    "        paragraphs.append(p.strip())\n",
    "\n",
    "# Extract requirements and decision points\n",
    "extracted_rules = []\n",
    "for idx, para in enumerate(paragraphs):\n",
    "    # Check for requirement keywords\n",
    "    if any(kw in para.lower() for kw in requirement_keywords):\n",
    "        # Try to extract citation and effective date from context\n",
    "        citation_match = re.search(r'(\\d+\\s*U\\.S\\.C\\.\\s*\\d+[a-zA-Z0-9\\(\\)]*)', para)\n",
    "        citation = citation_match.group(0) if citation_match else None\n",
    "        # Use known effective date from context if not found\n",
    "        effective_date = '2025-04-11'\n",
    "        # Build rule\n",
    "        rule = {\n",
    "            \"id\": f\"rule_{idx+1}\",\n",
    "            \"text\": para,\n",
    "            \"logic\": \"To be refined (AI-assisted translation)\",\n",
    "            \"metadata\": {\n",
    "                \"citation\": citation,\n",
    "                \"effective_date\": effective_date\n",
    "            }\n",
    "        }\n",
    "        extracted_rules.append(rule)\n",
    "\n",
    "# Display the extracted rules as JSON\n",
    "print(json.dumps(extracted_rules, indent=2))\n",
    "\n",
    "# Summary: This cell refines extraction by scanning for regulatory keywords and attempts to capture citations and effective dates for each rule. You can further refine logic or prompt AI to translate 'text' into executable code logic."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "NEPA Policy As Code",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
